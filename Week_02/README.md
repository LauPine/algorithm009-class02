# HashMap小总结

#### 数据结构

1. capacity始终是2的倍数,每次扩容为原来的两倍,默认值16,最大1 << 30
2. threshold = capacity * loadFactor(默认0.75)
3. TREEIFY_THRESHOLD,将链表优化为树结构的阀值,默认为8,还有几个和红黑树优化相关的参数
4. put操作
   1. 链表头节点为空,直接创建新节点
   2. 头节点key相同直接执行替换操作
   3. 头节点为TreeNode,转putTreeVal,执行红黑树的插入操作
   4. 遍历链表,找到则执行更新,找到链表尾端未找到则执行插入后检查是否需要优化链表
5. 扩容
   1. put操作触发扩容,桶长度小于MIN_TREEIFY_CAPACITY[默认64]时执行扩容
   2. size大于阀值时执行扩容
   3. 创建新数组-->扩容为原来容量2倍
   4. 进行数据转移-->长度为1的链表直接转移,TreeNode进行拆分,链表进行拆分移位
   5. 扩容操作是安全的,不会出现死循环,相对的顺序不会被打乱

# 哈希表

#### 定义

1. 散列表，根据keyvalue直接进行访问的数据结构，查询增加删除O(1)
2. 映射函数把keyvalue映射到表中一个位置index来访问记录，加快查找的速度
3. 这个映射函数叫做散列函数 ，存放记录的数组叫做哈希表

#### 哈希冲突

1. 哈希函数选的好的话会让数值尽量的分散，不会发生所谓的数值碰撞
2. 哈希表size太小或者哈希函数写的不好,导致哈希冲突
3. 解决冲突：增加维度，拉链式，链表，坏处在于一个数据查询O(1),最坏O(n)

# 二叉树

1. 注意所有左子树的点小于根节点，而不是左节点


# 二叉搜索树

1. 插入等操作时间复杂度：o(logn)
2. 删除：选择大于他的第一个节点替代

# 堆

1. heap：寻找一堆数中的最大值或者最小值的数据结构
2. 经常用于：一边数据进 另一边删除数据
3. 为什么不用数据排序来实现： 维护数组：每次有新元素插入都要重新排序 nO(logn) 删除也是 后面都要迁
4. 堆有多种： 大顶堆 小顶堆 二叉堆 斐波那契堆（时间空间复杂度更好 多叉树）
5. 二叉堆时间复杂度： find-max O(1) delete-max O(logn) insert O(logn)